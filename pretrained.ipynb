{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1715536459210
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1715536464996
        }
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # global mean and standard deviation of the RGB channels of the ImageNet dataset.\n",
        "])\n",
        "\n",
        "# Load data\n",
        "train_set = torchvision.datasets.ImageFolder(root='chest_xray/chest_xray/train', transform=transform)\n",
        "val_set = torchvision.datasets.ImageFolder(root='chest_xray/chest_xray/val', transform=transform)\n",
        "test_set = torchvision.datasets.ImageFolder(root='chest_xray/chest_xray/test', transform=transform)\n",
        "\n",
        "# Extract labels from the dataset\n",
        "train_labels = [label for _, label in train_set.imgs]\n",
        "\n",
        "# Count each class's samples to calculate weights\n",
        "class_counts = torch.tensor(\n",
        "    [(torch.tensor(train_labels) == t).sum() for t in torch.unique(torch.tensor(train_labels), sorted=True)]\n",
        ")\n",
        "\n",
        "# Calculate weight for each class\n",
        "weights = 1. / class_counts.float()\n",
        "\n",
        "# Assign a weight to each sample\n",
        "sample_weights = torch.tensor([weights[label] for label in train_labels])\n",
        "\n",
        "# Define the sampler with these sample weights\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=32, sampler=sampler)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1715536465502
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\akoza\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\akoza\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Model setup\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # '2' for Pneumonia/Normal classes\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# TensorBoard\n",
        "writer = SummaryWriter('runs/pneumonia_detection_experiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1715540149617
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [100/163], Loss: 0.1107\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "            writer.add_scalar('training loss', loss.item(), epoch * len(train_loader) + i)\n",
        "\n",
        "torch.save(model, 'model_pretrained.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1715540201764
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the test images: 86.69871794871794 %\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "    writer.add_scalar('test accuracy', 100 * correct / total, epoch)\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_loader):    \n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    y_proba = []\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            y_proba.extend(probabilities[:, 1].cpu().numpy())\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        # Calculate metrics\n",
        "        accuracy = correct / total\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "        TN, FP, FN, TP = cm.ravel()\n",
        "        specificity = TN / (TN + FP)\n",
        "        npv = TN / (TN + FN)  # Negative Predictive Value\n",
        "        auc = roc_auc_score(y_true, y_proba)\n",
        "\n",
        "        return accuracy, cm, precision, recall, f1_score, specificity, npv, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics on the train images\n",
            "Accuracy: 85.8974%\n",
            "Confusion Matrix:\n",
            "[[151  83]\n",
            " [  5 385]]\n",
            "Precision: 0.8226\n",
            "Recall: 0.9872\n",
            "F1 Score: 0.8974\n",
            "Specificity: 0.6453\n",
            "Negative Predictive Value: 0.9679\n",
            "AUC: 0.9369\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the evaluation function on train data\n",
        "accuracy, conf_matrix, precision, recall, f1_score, specificity, npv, auc = evaluate_model(model, train_loader)\n",
        "print(\"Metrics on the train images\")\n",
        "print(f\"Accuracy: {100* accuracy:.4f}%\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Precision: {100* precision:.4f}%\")\n",
        "print(f\"Recall: {100* recall:.4f}%\")\n",
        "print(f\"F1 Score: {100* f1_score:.4f}%\")\n",
        "print(f\"Specificity: {100* specificity:.4f}%\")\n",
        "print(f\"Negative Predictive Value: {100* npv:.4f}%\")\n",
        "print(f\"AUC: {100* auc:.4f}%\")\n",
        "\n",
        "print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics on the test images\n",
            "Accuracy: 0.8718\n",
            "Confusion Matrix:\n",
            "[[158  76]\n",
            " [  4 386]]\n",
            "Precision: 0.8355\n",
            "Recall: 0.9897\n",
            "F1 Score: 0.9061\n",
            "Specificity: 0.6752\n",
            "Negative Predictive Value: 0.9753\n",
            "AUC: 0.9398\n"
          ]
        }
      ],
      "source": [
        "# Call the evaluation function on test data\n",
        "accuracy, conf_matrix, precision, recall, f1_score, specificity, npv, auc = evaluate_model(model, test_loader)\n",
        "print(\"Metrics on the train images\")\n",
        "print(f\"Accuracy: {100* accuracy:.4f}%\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Precision: {100* precision:.4f}%\")\n",
        "print(f\"Recall: {100* recall:.4f}%\")\n",
        "print(f\"F1 Score: {100* f1_score:.4f}%\")\n",
        "print(f\"Specificity: {100* specificity:.4f}%\")\n",
        "print(f\"Negative Predictive Value: {100* npv:.4f}%\")\n",
        "print(f\"AUC: {100* auc:.4f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
